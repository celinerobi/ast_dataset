{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard packages\n",
    "import tempfile\n",
    "import warnings\n",
    "import urllib\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _base: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bfea0944de7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chip_allocate\\lib\\site-packages\\rasterio\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgdal_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrivers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdriver_from_extension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_blacklisted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m from rasterio.dtypes import (\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _base: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "# Less standard, but still pip- or conda-installable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import rasterio\n",
    "import re\n",
    "import rtree\n",
    "import shapely\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar # pip install progressbar2, not progressbar\n",
    "from geopy.geocoders import Nominatim\n",
    "from rasterio.windows import Window \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_eng.az_proc as ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Microsoft Azure Blob Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The(preferred) copy of NAIP in the West Europe Azure region\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the spatial index of NAIP tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bypassing download of already-downloaded file tile_index.dat\n",
      "Bypassing download of already-downloaded file tile_index.idx\n",
      "Bypassing download of already-downloaded file tiles.p\n"
     ]
    }
   ],
   "source": [
    "# Spatial index that maps lat/lon to NAIP tiles; we'll load this when we first \n",
    "# need to access it.\n",
    "index = None\n",
    "\n",
    "if index is None:\n",
    "    index = ap.NAIPTileIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.empty([0, 2])\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lons_lat_to_filepaths(lons, lats, index):\n",
    "    \"\"\"\n",
    "    Calculate file paths given lat and lat\n",
    "    \"\"\"\n",
    "    all_paths = np.empty(shape=(1,8))\n",
    "    for i in tqdm(range(len(lons))):\n",
    "        naip_file_pathways = index.lookup_tile(lats[i], lons[i])\n",
    "        if naip_file_pathways != None:\n",
    "            select_path = []\n",
    "            for ii in range(len(naip_file_pathways)):\n",
    "                tmp = naip_file_pathways[ii].split('/')\n",
    "                tmp = np.hstack((tmp, naip_file_pathways[ii].split('/')[3].split(\"_\")[1]))\n",
    "                iii = iter(tmp[5].split(\"_\",4))\n",
    "                tmp = np.hstack((tmp, list((map(\"_\".join,zip(*[iii]*4)) ))))\n",
    "                select_path.append(tmp)\n",
    "            select_path = np.array(select_path)\n",
    "            select_path = select_path[select_path[:,2] >= \"2018\"] #filter out years to get the most recent data that will include the highest resolution data\n",
    "\n",
    "            select_path = select_path[(select_path[:,6] == \"60cm\") | (select_path[:,6] == \"060cm\")] #select only pathways with 60cm\n",
    "                        \n",
    "            all_paths = np.vstack((all_paths, select_path)) #add to the rest of the paths\n",
    "            \n",
    "    file_pathways = np.delete(all_paths, 0, axis=0)\n",
    "\n",
    "    file_pathways = np.unique(file_pathways, axis=0) #select unique values\n",
    "    return file_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:00<00:00, 1354.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_sites = pd.read_csv(\"image_download_azure/identified_sites.csv\") #read in sheet of quadrangles\n",
    "expanded_sites_lat = expanded_sites[\"Lat\"].tolist()\n",
    "expanded_sites_lon = expanded_sites[\"Lon\"].tolist()\n",
    "assert len(expanded_sites_lat) == len(expanded_sites_lat)\n",
    "print(len(expanded_sites_lon))\n",
    "len(lons_lat_to_filepaths(expanded_sites_lon, expanded_sites_lat, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EIA and HFID Petroleum Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define filepathways to save data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set folder and specify destination\n",
    "natech_dir = os.path.join('/shared_space','natech') #use the shared_space folder as the base because there is ample storage capacilty \n",
    "os.makedirs(natech_dir,exist_ok=True)\n",
    "\n",
    "naip_dir = os.path.join(natech_dir,'naip') #directory for the naip data in the base (csr33) directory \n",
    "os.makedirs(naip_dir,exist_ok=True)\n",
    "\n",
    "naip_reshape_dir = os.path.join(natech_dir,'reshape') #directory to hold reshaped naip images\n",
    "os.makedirs(naip_reshape_dir,exist_ok=True)\n",
    "\n",
    "naip_chips_dir = os.path.join(natech_dir,'chips') #directory to hold reshaped naip images\n",
    "os.makedirs(naip_chips_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EIA and HFID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homeland Infrastructure Foundation-Level Data (HIFLD) - Petroleum Terminals\n",
    "\n",
    "https://hifld-geoplatform.opendata.arcgis.com/datasets/7841aba67178425cbf33995fc914e2fe_0/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfid_petroleum_terminals = pd.read_csv(\"image_download_azure/Petroleum_Terminals_HFID.csv\") #read in sheet of quadrangles\n",
    "hfid_lons = hfid_petroleum_terminals[\"X\"].tolist()\n",
    "hfid_lats = hfid_petroleum_terminals[\"Y\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EIA - Strategic Petroleum Reserves\n",
    "\n",
    "https://atlas.eia.gov/datasets/strategic-petroleum-reserves?geometry=-159.521%2C0.792%2C-28.212%2C52.750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_strategic_petroleum_reserves = pd.read_csv(\"image_download_azure/Strategic_Petroleum_Reserves.csv\") #read in sheet of quadrangles\n",
    "eia_spr_lons = eia_strategic_petroleum_reserves[\"X\"].tolist()\n",
    "eia_spr_lats = eia_strategic_petroleum_reserves[\"Y\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EIA - Petroleum Product Terminals\n",
    "\n",
    "https://atlas.eia.gov/datasets/petroleum-product-terminals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_petroleum_product_terminals = pd.read_csv(\"image_download_azure/Petroleum_Product_Terminals.csv\") #read in sheet of quadrangles\n",
    "eia_ppt_lons = eia_petroleum_product_terminals[\"X\"].tolist()\n",
    "eia_ppt_lats = eia_petroleum_product_terminals[\"Y\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EIA - Northeast Petroleum Reserves\n",
    "\n",
    "https://atlas.eia.gov/datasets/northeast-petroleum-reserves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_northeast_petroleum_reserves = pd.read_csv(\"image_download_azure/Northeast_Petroleum_Reserves.csv\") #read in sheet of quadrangles\n",
    "eia_npr_lons = eia_northeast_petroleum_reserves[\"X\"].tolist()\n",
    "eia_npr_lats = eia_northeast_petroleum_reserves[\"Y\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EIA - Petroleum Refineries\n",
    "\n",
    "https://atlas.eia.gov/datasets/petroleum-refineries?geometry=-13.914%2C-56.555%2C151.320%2C84.803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_petroleum_refineries = pd.read_csv(\"image_download_azure/Petroleum_Refineries.csv\") #read in sheet of quadrangles\n",
    "eia_pr_lons = eia_petroleum_refineries[\"X\"].tolist()\n",
    "eia_pr_lats = eia_petroleum_refineries[\"Y\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EIA - Natural Gas Processing Plants\n",
    "\n",
    "https://atlas.eia.gov/datasets/natural-gas-processing-plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_natural_gas_processing_plants = pd.read_csv(\"image_download_azure/Natural_Gas_Processing_Plants.csv\") #read in sheet of quadrangles\n",
    "eia_ngpp_lons = eia_natural_gas_processing_plants[\"X\"].tolist()\n",
    "eia_ngpp_lats = eia_natural_gas_processing_plants[\"Y\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Filepathways, tile name, tile URL for EIA HFID Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 251/2338 [00:00<00:02, 990.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 644/2338 [00:00<00:02, 782.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2338/2338 [00:05<00:00, 464.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 400.07it/s]\n",
      "  6%|▌         | 85/1476 [00:00<00:01, 849.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 261/1476 [00:00<00:01, 690.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 344/1476 [00:00<00:01, 736.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 552/1476 [00:00<00:01, 592.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 760/1476 [00:01<00:01, 618.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 952/1476 [00:01<00:00, 578.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1069/1476 [00:01<00:00, 554.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1179/1476 [00:02<00:00, 500.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1319/1476 [00:02<00:00, 416.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1412/1476 [00:02<00:00, 435.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [00:02<00:00, 532.15it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 856.42it/s]\n",
      " 46%|████▌     | 62/135 [00:00<00:00, 619.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 741.72it/s]\n",
      "100%|██████████| 478/478 [00:00<00:00, 1146.24it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 1477.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n",
      "No tile intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hfid_file_pathways = lons_lat_to_filepaths(hfid_lons, hfid_lats, index)\n",
    "eia_spr_file_pathways = lons_lat_to_filepaths(eia_spr_lons, eia_spr_lats, index)\n",
    "eia_ppt_file_pathways = lons_lat_to_filepaths(eia_ppt_lons, eia_ppt_lats, index)\n",
    "eia_npr_file_pathways = lons_lat_to_filepaths(eia_npr_lons, eia_npr_lats, index)\n",
    "eia_pr_file_pathways = lons_lat_to_filepaths(eia_pr_lons, eia_pr_lats, index)\n",
    "eia_ngpp_file_pathways = lons_lat_to_filepaths(eia_ngpp_lons, eia_ngpp_lats, index)\n",
    "expanded_file_pathways = lons_lat_to_filepaths(expanded_sites_lon, expanded_sites_lat, index)\n",
    "\n",
    "#filepathways \n",
    "petrol_file_pathways = np.vstack((hfid_file_pathways, eia_spr_file_pathways, eia_ppt_file_pathways, eia_npr_file_pathways,\n",
    "                                  eia_pr_file_pathways, eia_ngpp_file_pathways, expanded_file_pathways)) #combine filepaths from multiple sources\n",
    "\n",
    "petrol_file_pathways = np.unique(petrol_file_pathways, axis=0) remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tile names and urls \n",
    "tile_name_eia_hfid_expanded, tile_url_eia_hfid_expanded = ap.filepaths_to_tile_name_tile_url(petrol_file_pathways)\n",
    "tile_name_tile_url_eia_hfid_expanded = np.column_stack((tile_name_eia_hfid_expanded, tile_url_eia_hfid_expanded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2457, 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_name_tile_url_eia_hfid_expanded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Identified ASTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thirty Ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_port_quads = pd.read_csv(\"image_download_azure/Quadrangles_of_interest.csv\") #read in sheet of quadrangles\n",
    "\n",
    "tile_name_thirty_ports, tile_url_thirty_ports = ap.collected_quads_to_tile_name_tile_url(thirty_port_quads) # identify filespaths/urls for quads of interest\n",
    "\n",
    "tile_name_tile_url_thirty_ports = np.column_stack((tile_name_thirty_ports, tile_url_thirty_ports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Filepaths from each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2605, 2)\n",
      "(2535, 2)\n"
     ]
    }
   ],
   "source": [
    "tile_name_tile_url_eia_hfid_expanded_thirty_ports = np.vstack((tile_name_tile_url_eia_hfid_expanded, tile_name_tile_url_thirty_ports))\n",
    "print(tile_name_tile_url_eia_hfid_expanded_thirty_ports.shape)\n",
    "tile_name_tile_url_eia_hfid_expanded_thirty_ports = np.unique(tile_name_tile_url_eia_hfid_expanded_thirty_ports, axis=0) #remove duplicates\n",
    "print(tile_name_tile_url_eia_hfid_expanded_thirty_ports.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save tile name and url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save array Get array of the expanded data\n",
    "np.save(\"image_download_azure/tile_name_tile_url_eia_hfid_thirty_ports_expanded\", tile_name_tile_url_eia_hfid_expanded_thirty_ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_name_tile_url_eia_hfid_thirty_ports = np.load('image_download_azure/tile_name_tile_url_eia_hfid_thirty_ports.npy')\n",
    "dif = np.array(list(set(map(tuple, tile_name_tile_url_eia_hfid_expanded_thirty_ports)) - set(map(tuple, tile_name_tile_url_eia_hfid_thirty_ports ))))\n",
    "#save only the tiles that were not originally included in the assessment set\n",
    "np.save(\"image_download_azure/tile_name_tile_url_expanded_only\", dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_full = np.load(\"image_download_azure/tile_name_tile_url_eia_hfid_thirty_ports_expanded.npy\")\n",
    "expanded_only_additional = np.load(\"image_download_azure/tile_name_tile_url_expanded_only.npy\")\n",
    "labeled_first_set = np.load(\"tile_name_tile_url_labeled.npy\")\n",
    "#labeled_first_set_remaining = np.load(\"tile_name_tile_url_remaining.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://naipblobs.blob.core.windows.net/naip/v002/fl/2019/fl_60cm_2019/24081/m_2408126_ne_17_060_20191128.tif'\n",
      " 'https://naipblobs.blob.core.windows.net/naip/v002/fl/2019/fl_60cm_2019/24081/m_2408126_se_17_060_20191128.tif'\n",
      " 'https://naipblobs.blob.core.windows.net/naip/v002/fl/2019/fl_60cm_2019/25080/m_2508014_se_17_060_20191126.tif'\n",
      " ...\n",
      " 'https://naipblobs.blob.core.windows.net/naip/v002/wa/2019/wa_60cm_2019/48122/m_4812237_ne_10_060_20190806.tif'\n",
      " 'https://naipblobs.blob.core.windows.net/naip/v002/wa/2019/wa_60cm_2019/48122/m_4812258_se_10_060_20191011.tif'\n",
      " 'https://naipblobs.blob.core.windows.net/naip/v002/wa/2019/wa_60cm_2019/48122/m_4812258_sw_10_060_20191029.tif']\n",
      "(1151, 2)\n",
      "(1390, 2)\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "print(expanded_only_additional.shape)\n",
    "print(labeled_first_set.shape)\n",
    "print(labeled_first_set_remaining.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al' 'ar' 'az' 'ca' 'co' 'ct' 'de' 'fl' 'ga' 'ia' 'id' 'il' 'in' 'ks'\n",
      " 'ky' 'la' 'ma' 'md' 'me' 'mi' 'mn' 'mo' 'ms' 'mt' 'nc' 'nd' 'ne' 'nh'\n",
      " 'nj' 'nm' 'nv' 'ny' 'oh' 'ok' 'pa' 'ri' 'sc' 'sd' 'tn' 'tx' 'ut' 'va'\n",
      " 'vt' 'wa' 'wi' 'wv' 'wy']\n"
     ]
    }
   ],
   "source": [
    "states = []\n",
    "for tile in expanded_full[:,1]:\n",
    "    states.append(tile.split(\"/\")[5])\n",
    "print(np.unique(np.array(states)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chip Allocate",
   "language": "python",
   "name": "chip_allocate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
