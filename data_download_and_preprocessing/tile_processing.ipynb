{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29abde2c-fb9e-4cbb-b7bd-c4354a0662ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import fiona #must be import before geopandas\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import re\n",
    "import rtree\n",
    "import shapely\n",
    "import pickle\n",
    "\n",
    "#from cartopy import crs\n",
    "import collections\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "# Standard packages\n",
    "import tempfile\n",
    "import warnings\n",
    "import urllib\n",
    "import shutil\n",
    "\n",
    "# Less standard, but still pip- or conda-installable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import data_eng.az_proc as ap\n",
    "import data_eng.form_calcs as fc\n",
    "\n",
    "from lxml.etree import Element,SubElement,tostring\n",
    "import xml.dom.minidom\n",
    "from xml.dom.minidom import parseString\n",
    "import xml.etree.ElementTree as et\n",
    "from xml.dom import minidom\n",
    "\n",
    "#import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import tqdm\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "import imutils\n",
    "\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7e748-9371-4b89-9102-369f351add13",
   "metadata": {},
   "outputs": [],
   "source": [
    "File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7477b366-2da9-4f37-bb96-80c1ca102588",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = \"//oit-nas-fe13dc.oit.duke.edu//data_commons-borsuk//\"\n",
    "\n",
    "tile_names_tile_urls_complete_array = np.load(\"image_download_azure/tile_name_tile_url_complete_array.npy\")\n",
    "\n",
    "tiles_labeled = \"tile_name_tile_url_labeled.npy\"\n",
    "tiles_labeled_from_complete_set = np.load(tiles_labeled)\n",
    "\n",
    "tracker_file_path = 'outputs/tile_img_annotation_annotator.npy'\n",
    "tile_img_annotation = np.load(tracker_file_path)\n",
    "tile_img_annotation_annotator = np.load(\"outputs/tile_img_annotation_annotator.npy\")\n",
    "\n",
    "tiles_errors = 'tile_name_tile_url_error_downloading.npy'\n",
    "tiles_errors = np.load(tiles_errors)\n",
    "\n",
    "#create folder to hold tiles in completed dataset\n",
    "\n",
    "tiles_complete_dataset_path = os.path.join(parent_directory,\"complete_dataset\",\"tiles\")\n",
    "tiles_xml_complete_dataset_path = os.path.join(parent_directory,\"complete_dataset\",\"tiles_xml\")\n",
    "os.makedirs(tiles_complete_dataset_path, exist_ok=True)\n",
    "\n",
    "tile_names_tile_urls_complete_array_unique_standard_tile_names = np.load(\"tile_names_tile_urls_complete_array_unique_standard_tile_names.npy\")\n",
    "image_characteristics = pd.read_csv(\"image_characteristics.csv\")\n",
    "tile_names_tile_urls_complete_array_unique_standard_tile_names = np.load(\"tile_names_tile_urls_complete_array_unique_standard_tile_names.npy\")\n",
    "\n",
    "#NAIP quad map\n",
    "quad_indicies_path = \"C:/Users/rapiduser/Box/EPA STAR 2019 (Community Resistance to Environmental Disasters)/Data/AST Datasets/MapIndices_National_GDB/MapIndices_National_GDB.gdb\"\n",
    "#fiona.listlayers(quad_indicies_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e99389-3ba4-4962-97fc-0ab2b100b93a",
   "metadata": {},
   "source": [
    "Unverified Images and Annotations (Subfolders, Images, and XMLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63d727f-409c-419f-a654-b4dfb92d3151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:03<00:00, 10.83it/s]\n"
     ]
    }
   ],
   "source": [
    "unverified_set1_subfolders_path = os.path.join(parent_directory,\"unverified_images\\student_reviewed_unverified_images_set1\")\n",
    "unverified_set1_subfolders_path = ap.img_path_anno_path(ap.list_of_sub_directories(unverified_set1_subfolders_path))\n",
    "\n",
    "unverified_set1_image_paths = []\n",
    "unverified_set1_xml_paths = []\n",
    "for directory in tqdm.tqdm(unverified_set1_subfolders_path):\n",
    "    #print(len(os.listdir(directory[0])),len(os.listdir(directory[1])))\n",
    "    fc.remove_thumbs(directory[0])\n",
    "    unverified_set1_image_paths += glob(directory[0] + \"/*.jpg\", recursive = True)\n",
    "    unverified_set1_xml_paths += glob(directory[1] + \"/*.xml\", recursive = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c61216-410d-46d5-8083-8cb5ede7a81d",
   "metadata": {},
   "source": [
    "Verified Images and Annotations (Subfolders, Images, and XMLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5e289a-064c-4b4e-8972-2a3c47ab92ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:04<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "verified_sets_path = os.path.join(parent_directory, \"verified/verified_sets\")\n",
    "verified_sets_subfolders_path = ap.img_path_anno_path(ap.list_of_sub_directories(verified_sets_path))\n",
    "\n",
    "verified_set1_image_paths = []\n",
    "verified_set1_xml_paths = []\n",
    "verified_set1_subfolders_path = []\n",
    "\n",
    "for verified_set in tqdm.tqdm(verified_sets_subfolders_path):\n",
    "    fc.remove_thumbs(verified_set[0])\n",
    "    set_number = verified_set[0].split(\"/\")[-2].split(\"_\")[1]\n",
    "    \n",
    "    if set_number == str(1):\n",
    "        verified_set1_image_paths += glob(verified_set[0] + \"/*.jpg\", recursive = True)\n",
    "        verified_set1_xml_paths += glob(verified_set[1] + \"/*.xml\", recursive = True)\n",
    "        verified_set1_subfolders_path.append(verified_set)\n",
    "        \n",
    "verified_set1_subfolders_path = np.array(verified_set1_subfolders_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb13313-e0d0-419c-9d8e-f514f52b1afe",
   "metadata": {},
   "source": [
    "Unverified and Verified Images and Annotations (Subfolders, Images, and XMLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b361b77-fccb-4ac7-bdd3-e3a934c49482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first folder in unverified\n",
    "#get directories that need to be check\n",
    "fc.remove_thumbs(tiles_complete_dataset_path)\n",
    "unverified_verified_set1_image_paths = np.array(unverified_set1_image_paths + verified_set1_image_paths)\n",
    "unverified_verified_set1_subfolders_paths = np.concatenate((unverified_set1_subfolders_path, verified_set1_subfolders_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e293d26-d027-4262-8c15-b02aca642799",
   "metadata": {},
   "source": [
    "Identify labeled images where the images do not correspond correctly to the tile chip <br>\n",
    "(identified by subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69459e5b-cf15-46b3-ae3b-2eba236ae078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive_images = np.zeros((0, 512, 512, 3))\n",
    "tile_names = []\n",
    "incorrect_chip_names =[]\n",
    "incorrect_chip_paths = []\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for directory in tqdm.tqdm(unverified_verified_set1_subfolders_paths):\n",
    "    #identify tiles that have corresponding images in directory\n",
    "    tiles_in_directory = fc.get_tile_names_from_chip_names(directory[0])\n",
    "    images_in_directory, images_in_directory_array, image_directory = fc.positive_images_to_array(directory[0])\n",
    "    tile_names_temp, xs_temp, ys_temp, incorrect_chip_names_temp, incorrect_chip_paths_temp = fc.identify_incorrect_images(tiles_complete_dataset_path, tiles_in_directory, \n",
    "                                                                                                                           images_in_directory, images_in_directory_array,\n",
    "                                                                                                                           image_directory)\n",
    "    tile_names += tile_names_temp\n",
    "    xs += xs_temp \n",
    "    ys += ys_temp \n",
    "    incorrect_chip_paths += incorrect_chip_paths_temp \n",
    "    incorrect_chip_names += incorrect_chip_names_temp\n",
    "\n",
    "d = {'tile_names': tile_names,\n",
    "     'xs': xs,\n",
    "     'ys': ys,\n",
    "     'incorrect_chip_paths': incorrect_chip_paths,\n",
    "     'incorrect_chip_names': incorrect_chip_names}\n",
    "\n",
    "incorrect_labeled_chip_names = pd.DataFrame(data = d)\n",
    "incorrect_labeled_chip_names.to_csv('incorrect_labeled_chip_names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2f39d-ae12-4f5b-a72d-25a395308497",
   "metadata": {},
   "source": [
    "Identify labeled images where the images do not correspond correctly to the tile chip <br>\n",
    "(identified by tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57f591-2680-427e-9a4d-7345c55a5abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:03<00:00, 12.92it/s]\n",
      " 96%|█████████▌| 891/932 [5:01:51<11:41, 17.11s/it]  "
     ]
    }
   ],
   "source": [
    "fc.remove_thumbs(tiles_complete_dataset_path)\n",
    "\n",
    "tiles_in_set1 = np.zeros((0))\n",
    "for subfolders in tqdm.tqdm(unverified_verified_set1_subfolders_paths):\n",
    "    tiles_in_set1 = np.concatenate((tiles_in_set1, fc.get_tile_names_from_chip_names(subfolders[0])))\n",
    "tiles_in_set1 = np.unique(tiles_in_set1)\n",
    "\n",
    "tile_names, xs, ys, incorrect_chip_paths = fc.identify_incorrect_images_simultaneous(tiles_complete_dataset_path, tiles_in_set1, unverified_verified_set1_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac5b28-1dc2-4c0a-9fde-e1d5a290590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'tile_names': tile_names,\n",
    "     'xs': xs,\n",
    "     'ys': ys,\n",
    "     'incorrect_chip_paths': incorrect_chip_paths}\n",
    "\n",
    "incorrect_labeled_chip_names_by_tile = pd.DataFrame(data = d)\n",
    "incorrect_labeled_chip_names_by_tile.to_csv('incorrect_labeled_chip_names_by_tile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887d0b4-f31c-4c10-9e5f-ba979b9abee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive_images = np.zeros((0, 512, 512, 3))\n",
    "tile_names = []\n",
    "incorrect_chip_names =[]\n",
    "incorrect_chip_paths = []\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for directory in tqdm.tqdm(unverified_verified_set1_subfolders_paths):\n",
    "    #identify tiles that have corresponding images in directory\n",
    "    tiles_in_directory = fc.get_tile_names_from_chip_names(directory[0])\n",
    "    images_in_directory, images_in_directory_array, image_directory = fc.positive_images_to_array(directory[0])\n",
    "    tile_names_temp, xs_temp, ys_temp, incorrect_chip_names_temp, incorrect_chip_paths_temp = fc.identify_incorrect_images(tiles_complete_dataset_path, tiles_in_directory, \n",
    "                                                                                                                           images_in_directory, images_in_directory_array,\n",
    "                                                                                                                           image_directory)\n",
    "    tile_names += tile_names_temp\n",
    "    xs += xs_temp \n",
    "    ys += ys_temp \n",
    "    incorrect_chip_paths += incorrect_chip_paths_temp \n",
    "    incorrect_chip_names += incorrect_chip_names_temp\n",
    "\n",
    "d = {'tile_names': tile_names,\n",
    "     'xs': xs,\n",
    "     'ys': ys,\n",
    "     'incorrect_chip_paths': incorrect_chip_paths,\n",
    "     'incorrect_chip_names': incorrect_chip_names}\n",
    "\n",
    "incorrect_labeled_chip_names_by_subfolder = pd.DataFrame(data = d)\n",
    "incorrect_labeled_chip_names_by_subfolder.to_csv('incorrect_labeled_chip_names_by_subfolder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356237c-1136-4a20-b292-8fa1577d9eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa679f82-e8fc-4aec-a018-7dfa6e48660e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a629a-eabf-4ef3-bb33-7deffa88bd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f24ca9-f08c-4707-9c0d-764a8bed88f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ef697-d496-4302-9357-b860bdbf23a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47f293-2c3b-4623-bc39-aa2aa7d94626",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(unverified_verified_set1_image_paths == unverified_verified_set1_image_paths[0])\n",
    "print(index)\n",
    "#labeled_chip_array = cv2.imread(os.path.join(images_path[index[0]])) #open image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb359dfe-f0f9-4aae-a157-640fd5740b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.array(unverified_set1_image_paths + verified_set1_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24cd11-3b28-4925-834c-c3b11e86a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first folder in unverified\n",
    "#get directories that need to be check\n",
    "\n",
    "    \n",
    "    \n",
    "#positive_images = np.zeros((0, 512, 512, 3))\n",
    "\n",
    "#identify tiles that have corresponding images in directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab177a-908f-442c-99b4-8d03e8f79cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_images_to_array(images_dir_path):\n",
    "    \n",
    "    image_array = np.zeros((len(images),512,512, 3), dtype='uint8')\n",
    "    image_directory = np.array([images_dir_path] *len(images))\n",
    "    for num in range(len(images)):    \n",
    "        image = cv2.imread(os.path.join(images_dir_path, images[num])) #open image\n",
    "        image_array[num,:,:,:] = image\n",
    "        \n",
    "    return(images, image_array, image_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a357a-e67a-4807-a18b-d531a19a7467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d671d-c105-42cb-92b4-389796281f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bab037-cbaa-4240-ac09-6ec48cb2804c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34068813-b002-44fa-8af8-2a982a7a007b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7d34a-87c3-41bc-ba32-0db3d779ead5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c4fbf-33f6-46e0-a5d6-3c5f97d7893c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6f37f-bb8f-4eb0-a63c-efcef6a756cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e12996-d774-4efd-b694-58fb5138342d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99161be5-14c3-43b5-9f32-5cb32febb48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78d292-dde3-4c0c-abc1-9b0928ecdbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_images_from_chipped_tile_for_positive_images(tile_dir, tiles_in_directory, images_in_directory_array):\n",
    "    \"\"\"\n",
    "    Find images that do not align with the tile chip\n",
    "    \n",
    "    \"\"\"\n",
    "    #index over the tiles with corresponding images in the given directory\n",
    "    correct_images = np.zeros((0, 512, 512, 3))\n",
    "    correct_standard_chip_names = []\n",
    "\n",
    "    for tile_name in tiles_in_directory: \n",
    "        file_name, ext = os.path.splitext(tile_name) # File name\n",
    "        \n",
    "        #get tile shape\n",
    "        item_dim = int(512)          \n",
    "        tile = cv2.imread(os.path.join(tile_dir, tile_name)) \n",
    "        tile_height,  tile_width,  tile_channels = tile.shape #the size of the tile #determine tile dimensions\n",
    "        row_index = math.ceil(tile_height/512) #divide the tile into 512 by 512 chips (rounding up)\n",
    "        col_index = math.ceil(tile_width/512)\n",
    "\n",
    "        count = 1 #image names start at 1 \n",
    "        \n",
    "        for y in range(0, col_index):\n",
    "            for x in range(0, row_index):\n",
    "                chip_name = file_name + '_' + str(count).zfill(6) + '.jpg'\n",
    "                \n",
    "                #create a numpy array of each correctly chipped images \n",
    "                correct_image = tile_to_chip_array(tile, x, y, item_dim)\n",
    "                count += 1  \n",
    "                for labeled_image in images_in_directory_array:\n",
    "                    ##https://pyimagesearch.com/2017/06/19/image-difference-with-opencv-and-python/\n",
    "                    #https://pyimagesearch.com/2014/09/15/python-compare-two-images/\n",
    "                    gray_labeled_image = cv2.cvtColor(labeled_image, cv2.COLOR_BGR2GRAY)\n",
    "                    gray_correct_image = cv2.cvtColor(correct_image, cv2.COLOR_BGR2GRAY)\n",
    "                    (score, diff) = compare_ssim(gray_labeled_image, gray_correct_image, full=True)\n",
    "                    diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "                    if score > 0.90: #Save the same images\n",
    "                        print(\"same image\")\n",
    "                        correct_images.concatenate(correct_image)\n",
    "                        correct_standard_chip_names.append(chip_name)\n",
    "                        print(\"SSIM: {}\".format(score))\n",
    "\n",
    "    return(correct_images, correct_standard_chip_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b3ce2-8ca5-4a3e-80b3-c740c43879b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with incorrectly labeled images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e848c-0f1f-4be0-92ad-121475663414",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a37228-e9b6-4da2-bd72-56051b3addb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff539c47-eb6c-4497-bb47-f30496ca260b",
   "metadata": {},
   "source": [
    "### Identifical duplicate tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a299454-3e06-4f35-9b47-9f997244f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset_chips_positive_path = os.path.join(parent_directory,\"complete_dataset/chips_positive\")\n",
    "complete_dataset_chips_positive = os.listdir(complete_dataset_chips_positive_path)\n",
    "#for chip in complete_dataset_chips_positive:\n",
    "#complete_dataset_chips_positive[0].split[_]\n",
    "fc.remove_thumbs(complete_dataset_chips_positive_path)\n",
    "formatted_tiles = []\n",
    "for path in complete_dataset_chips_positive:\n",
    "    img = os.path.splitext(path)[0] #name of tif with the extension removed\n",
    "    tile = img.rsplit(\"_\",1)[0]\n",
    "    #print(tile)\n",
    "    formatted_tiles.append(tile)\n",
    "    \n",
    "formatted_tiles = np.unique(formatted_tiles)\n",
    "len(formatted_tiles)\n",
    "\n",
    "\n",
    "standard_tiles = []\n",
    "for tile in formatted_tiles:\n",
    "    standard_tiles.append(tile.split(\"_\",4)[4]) #get the tile names to remove duplicates from being downloaded\n",
    "    \n",
    "u, c = np.unique(standard_tiles, return_counts = True)\n",
    "duplicate_tiles = u[c > 1]\n",
    "len(duplicate_tiles)\n",
    "duplicate_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe550d3-af4f-47bf-99c2-fb0c31a7f56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dcbb74-c452-4494-b3ce-d91db502152a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e76c5-45b6-47a0-9b78-9969a010d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index over images that do not match \n",
    "index, = np.where(correct_0_incorrect_1_images == 1)\n",
    "image_in_directory_array = images_in_directory_array[index[0]] #use the actual value of index (saved as an array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24187ac2-1fa7-4ebc-b3b4-39f3ccc8c3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2269384c-ac5e-4b6f-95a5-d871d83eb648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e17d10-36db-4f0c-9559-d6f36f99e3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d93ee7-c28b-43bc-9b7e-de9687d23c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627d445-3613-4b4b-8d6d-84261070061c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b137f36-ede6-480f-a215-5656dfa9bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in range(len(chip_names)):\n",
    "    if path exists \n",
    "    -1\n",
    "    \n",
    "def identify_incorrect_images(tile_dir, tiles_in_directory, \n",
    "                          images_in_directory, images_in_directory_array, directory[0]):\n",
    "    \"\"\"\n",
    "    Find images that do not align with the tile chip\n",
    "    \"\"\"\n",
    "    #index over the tiles with corresponding images in the given directory\n",
    "    tile_names = []\n",
    "    incorrect_chip_names = []\n",
    "    incorrect_chip_paths = []\n",
    "    #same_image_counter = 0\n",
    "    for tile_name in tiles_in_directory: \n",
    "        file_name, ext = os.path.splitext(tile_name) # File name\n",
    "        \n",
    "        #get tile shape\n",
    "        item_dim = int(512)          \n",
    "        tile = cv2.imread(os.path.join(tile_dir, tile_name)) \n",
    "        tile_height,  tile_width,  tile_channels = tile.shape #the size of the tile #determine tile dimensions\n",
    "        row_index = math.ceil(tile_height/512) #divide the tile into 512 by 512 chips (rounding up)\n",
    "        col_index = math.ceil(tile_width/512)\n",
    "\n",
    "        count = 1  \n",
    "        for y in range(0, col_index):\n",
    "            for x in range(0, row_index):\n",
    "                chip_name_temp = file_name+ '_' + str(count).zfill(6) + '.jpg'\n",
    "                #create a numpy array of each correctly chipped images \n",
    "                correct_image = tile_to_chip_array(tile, x, y, item_dim)\n",
    "                count += 1  \n",
    "\n",
    "                #Identify if images that are contained in the directory of interest\n",
    "                confirmed_chips = [string for string in images_in_directory if chip_name_temp in string]\n",
    "                if len(confirmed_chips) > 0:\n",
    "                    for confirmed_chip in confirmed_chips: #there may be duplicate images corresponding to the same standard tile name (nj and ny overlap)\n",
    "                    #obtain a numpy array of the image in the directory of interest\n",
    "                        index, = np.where(images_in_directory == confirmed_chip)\n",
    "                        image_in_directory_array = images_in_directory_array[index[0]] #use the actual value of index (saved as an array)\n",
    "\n",
    "                        ##https://pyimagesearch.com/2017/06/19/image-difference-with-opencv-and-python/\n",
    "                        #https://pyimagesearch.com/2014/09/15/python-compare-two-images/\n",
    "                        gray_image_in_directory_array = cv2.cvtColor(image_in_directory_array, cv2.COLOR_BGR2GRAY)\n",
    "                        gray_correct_image = cv2.cvtColor(correct_image, cv2.COLOR_BGR2GRAY)\n",
    "                        (score, diff) = compare_ssim(gray_image_in_directory_array, gray_correct_image, full=True)\n",
    "                        diff = (diff * 255).astype(\"uint8\")\n",
    "                        \n",
    "                        correct_image_paths.append(os.path.join(directory[0],confirmed_chip))\n",
    "\n",
    "\n",
    "                        #if score >= 0.90: \n",
    "                        #    same_image_counter +=1\n",
    "                        if score < 0.90: \n",
    "                            print(\"different image\")\n",
    "                            tile_names.append(tile_name)\n",
    "                            xs.append(x)\n",
    "                            ys.append(y)\n",
    "                            incorrect_chip_namess.append(confirmed_chip)\n",
    "                            incorrect_chip_paths.append(os.path.join(directory[0],confirmed_chip))\n",
    "                            tiles_dir.append( tile_dir)\n",
    "                            print(\"SSIM: {}\".format(score))\n",
    "                            #fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "                            #ax1.imshow(correct_image)\n",
    "                            #ax2.imshow(image_in_directory_array)\n",
    "                            #plt.show() \n",
    "    return(tile_names, xs, ys, chip_names, tiles_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c372a-59b2-4c10-80b8-7438a660df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Deal with duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3722e-af29-4929-b2c4-fc812856d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first folder in unverified\n",
    "#get directories that need to be chec\n",
    "\n",
    "tile_names = []\n",
    "xs = []\n",
    "ys = []\n",
    "chip_names = []\n",
    "tiles_dir = []\n",
    "for directory in tqdm.tqdm(unverified_set1_subfolders_path):\n",
    "    #identify tiles that have corresponding images in directory\n",
    "    tiles_in_directory = get_tile_names_from_chip_names(directory[0])\n",
    "\n",
    "    #check data that needs to be checked\n",
    "    images_in_directory, images_in_directory_array, image_directory_array = positive_images_to_array_v2(directory[0])\n",
    "\n",
    "    tile_names_temp, xs_temp, ys_temp, chip_names_temp, tiles_dir_temp = confirm_correct_image(tiles_complete_dataset_path, tiles_in_directory, images_in_directory, images_in_directory_array)\n",
    "    tile_names += tile_names_temp\n",
    "    xs += xs_temp\n",
    "    ys += ys_temp\n",
    "    chip_names += chip_names_temp \n",
    "    tiles_dir += tiles_dir_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933be7ce-b762-4aff-9003-38c8d665eccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aed09b-494c-486a-828c-732692710ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65512cb-ed25-43ca-a068-e55041820fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48904f24-319e-479f-a0ca-ca6ccfc2b0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da950a-58d1-41c4-890b-03a481301489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00413917-bdc5-4357-a634-a533e033880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c553b-7663-417d-a8b9-66c9a52dd1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c9adf-30a3-47f1-a2a2-42066136e660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a6cbd-b378-4d6a-ab33-ad21cb8e7e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9d4e55b-2c76-4a65-92ba-8a97a5404ee9",
   "metadata": {},
   "source": [
    "There are possibly duplicate images that are misnamed from when Qianyu was in charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabf8cc-8d34-4045-a7ba-49d7cc5a1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.remove_thumbs(\"C:/chip_allocation/complete_dataset/chips_positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b0e34-1e69-449b-850e-6fbaa201926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = []\n",
    "resolution = []\n",
    "year = []\n",
    "capture_date  = []\n",
    "utm_zone  = []\n",
    "\n",
    "standard_tile_names = []\n",
    "chip_names = []\n",
    "NW_coordinates = []\n",
    "SE_coordinates = []\n",
    "row_indicies = []\n",
    "col_indicies = []\n",
    "full_path  = []\n",
    "root = []\n",
    "for tile_name in tqdm.tqdm(['m_4009152_se_15_060_20190728.tif']): #index over the tiles in the tiles_dir \n",
    "    file_name, ext = os.path.splitext(tile_name) # File name\n",
    "    print(tile_name)\n",
    "    count = 1      \n",
    "\n",
    "    item_dim = int(512)          \n",
    "    tile = cv2.imread(os.path.join(tiles_dir, tile_name)) \n",
    "    tile_height,  tile_width,  tile_channels = tile.shape #the size of the tile \n",
    "    print(tile_height,tile_width)\n",
    "\n",
    "    #divide the tile into 512 by 512 chips (rounding up)\n",
    "    row_index = math.ceil(tile_height/512) \n",
    "    col_index = math.ceil(tile_width/512)\n",
    "    print(row_index*512,col_index*512)\n",
    "\n",
    "    for x in range(0, col_index):\n",
    "        for y in range(0, row_index):\n",
    "            #Tile names no longer match chip file names!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            chip_name_temp = file_name+ '_'+ str(count).zfill(6) + '.jpg'\n",
    "            count += 1  \n",
    "            if len(verified_positive_jpgs[verified_positive_jpgs[:,0] == chip_name_temp]) > 0: #only record values for images that are annotated\n",
    "                #image characteristics\n",
    "                chip_names.append(chip_name_temp) # The index is a six-digit number like '000023'.\n",
    "                NW_coordinates.append([x*item_dim, y*(item_dim)]) #NW (Top Left) \n",
    "                SE_coordinates.append([x*item_dim+item_dim-1, y*(item_dim)+item_dim-1]) #SE (Bottom right) \n",
    "                row_indicies.append(y)\n",
    "                col_indicies.append(x)\n",
    "                #tile characteristics\n",
    "                ##  Get tile url using tile name\n",
    "                standard_tile_names.append(tile_name)\n",
    "                #path\n",
    "                full_path = verified_positive_jpgs[verified_positive_jpgs[:,0] == chip_name_temp][0][1]\n",
    "                root = full_path.split(\"\\\\\",2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b635c1-a550-4102-98ab-028a433a9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_names\n",
    "m_4009152_se_15_060_20190728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56f729-7f75-4350-a951-4163dacd5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_names_tile_urls_complete_array_unique_standard_tile_names[tile_names_tile_urls_complete_array_unique_standard_tile_names[:,0]==\"m_3812263_sw_10_060_20180723_20190210.tif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ed85d-17b5-420f-b71f-1f166b992474",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_name_tile_url = np.load('image_download_azure/tile_name_tile_url_complete_array.npy')\n",
    "tile_name_tile_url[tile_name_tile_url[:,0]=='m_3812263_sw_10_060_20180723_20190210.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47946f3-9886-45bd-b48d-0296f512ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.download_url(tile_names_tile_urls_complete_array_unique_standard_tile_names[tile_names_tile_urls_complete_array_unique_standard_tile_names[:,2]==\"m_3812263_sw_10_060_20180723\"][0][1],\n",
    "                \"C:/chip_allocation/test/tiles\",\n",
    "                destination_filename = tile_names_tile_urls_complete_array_unique_standard_tile_names[tile_names_tile_urls_complete_array_unique_standard_tile_names[:,2]==\"m_3812263_sw_10_060_20180723\"][0][0],       \n",
    "                progress_updater=ap.DownloadProgressBar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fa61d-ef87-4d31-8b48-2b2006b65d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile_name in os.listdir(\"C:/chip_allocation/test/tiles\"): #index over the tiles in the tiles_dir \n",
    "    file_name, ext = os.path.splitext(tile_name) # File name\n",
    "    print(tile_name)\n",
    "    item_dim = int(512)\n",
    "    count = 1            \n",
    "    tile = cv2.imread(os.path.join(\"C:/chip_allocation/test/tiles\", tile_name)) \n",
    "    tile_height,  tile_width,  tile_channels = tile.shape #the size of the tile \n",
    "\n",
    "    #divide the tile into 512 by 512 chips (rounding up)\n",
    "    row_index = math.ceil(tile_height/512) \n",
    "    col_index = math.ceil(tile_width/512)\n",
    "    #print(row_index, col_index)\n",
    "\n",
    "    for y in range(0, col_index):\n",
    "        for x in range(0, row_index):\n",
    "            chip_img = tile[y*item_dim:y*item_dim+item_dim, x*(item_dim):x*(item_dim)+item_dim]\n",
    "\n",
    "            #specify the path to save the image\n",
    "            chips_save_path = os.path.join(\"C:/chip_allocation/test/chips\", file_name+ '_'+ \\\n",
    "                       str(count).zfill(6) + '.jpg') # The index is a six-digit number like '000023'.\n",
    "\n",
    "            #add in back space if it is the edge of an image\n",
    "            if chip_img.shape[0] != 512:  #Height\n",
    "                #print(\"Incorrect Height\")\n",
    "                black_height = 512  - chip_img.shape[0] #Height\n",
    "                black_width = 512 #- chip_img.shape[1] #width\n",
    "                black_img = np.zeros((black_height,black_width,3), np.uint8)\n",
    "                #print(black_img.shape[0]) #Height\n",
    "                #print(black_img.shape[1]) #width\n",
    "                chip_img = np.concatenate([chip_img, black_img])\n",
    "\n",
    "            if chip_img.shape[1] != 512: #width\n",
    "                #print(\"Incorrect Width\")\n",
    "                black_height = 512 #- chip_img.shape[0] #Height\n",
    "                black_width = 512 - chip_img.shape[1] #width\n",
    "                black_img = np.zeros((black_height,black_width,3), np.uint8)\n",
    "                #print(black_img.shape[0]) #Height\n",
    "                #print(black_img.shape[1]) #width\n",
    "                chip_img = np.concatenate([chip_img, black_img],1)\n",
    "\n",
    "            #save image\n",
    "            cv2.imwrite(os.path.join(chips_save_path), chip_img)    \n",
    "            #counter for image pathway\n",
    "            count += 1  \n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283f630-8e12-48a4-addb-fd0fd1b97e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tile names and urls for all tiles apart of the dataset (complete array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f6edc-95c5-4364-a66f-58321eaec6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_names_tile_urls_complete_array = fc.add_formatted_and_standard_tile_names_to_tile_names_time_urls(tile_names_tile_urls_complete_array)\n",
    "print(tile_names_tile_urls_complete_array.shape)\n",
    "\n",
    "tile_names_tile_urls_complete_array_unique_standard_tile_names, tile_names_tile_urls_complete_array_unique_formatted_tile_names = fc.unique_formatted_standard_tile_names(tile_names_tile_urls_complete_array)\n",
    "#Save unique standard tile names\n",
    "np.save(\"tile_names_tile_urls_complete_array_unique_standard_tile_names.npy\", tile_names_tile_urls_complete_array_unique_standard_tile_names)\n",
    "#pd.DataFrame(np.load(\"image_download_azure/tile_name_tile_url_complete_array.npy\")).to_csv(\"image_download_azure/tile_name_tile_url_complete_array.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11663a1-96c3-4a83-b97c-ac1435a43c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xml_path_from_root_jpg(df, i):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    file_name = os.path.splitext(df.six_digit_chip_name[i])[0]\n",
    "    xml_path = os.path.join(df.root[i], \"chips_positive_xml\", file_name + \".xml\") #review how root path was formed \n",
    "    tree = et.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    return(xml_path,root)\n",
    "\n",
    "def generate_xml(tile_name, tiles_path, tiles_xml_path, tile_bands, tile_height, tile_width):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #https://www.geeksforgeeks.org/create-xml-documents-using-python/\n",
    "    #root = et.Element(\"annotation\")\n",
    "      \n",
    "    #filename = et.Element(\"filename\")\n",
    "    #filename.text = tile_name + \".tif\" #tilename\n",
    "    #root.append(filename)\n",
    "    \"\"\"\n",
    "    path = et.Element(\"path\") \n",
    "    path.text = tiles_path   #path of database (tiles)\n",
    "    root.append(path)\n",
    "    \n",
    "    source = et.Element(\"source\")\n",
    "    root.append(source)\n",
    "    database = et.SubElement(source, \"database\")\n",
    "    database.text = \"AST Dataset - Complete Tile\" #name of database\n",
    "\n",
    "    \n",
    "\n",
    "    size = et.Element(\"size\")\n",
    "    root.append(size)\n",
    "    width = et.SubElement(size, \"width\")\n",
    "    width.text = tile_width #tile width\n",
    "    height = et.SubElement(size, \"height\")\n",
    "    height.text = tile_height #tile height\n",
    "    depth = et.SubElement(size, \"depth\")\n",
    "    depth.text = tile_bands #tile depth\n",
    "    \"\"\"   \n",
    "    #tree = et.ElementTree(root)\n",
    "    tile_xml_path = os.path.join(tiles_xml_path, tile_name + \".xml\")\n",
    "    print(tile_xml_path)\n",
    "    #with open (os.path(tiles_xml_complete_dataset_path, tile_name + \".xml\"), \"wb\") as files :\n",
    "    #    tree.write(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35b501f-6d7d-4fbe-97b8-57943c0f1ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16004eca-7adb-4d42-a278-c999b30afbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_complete_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e172bcf-ddea-48dc-ba49-b0e8db39d65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9520c2-1b8e-480a-ae0a-0eac1c38a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_positive_jpgs\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225e9a4-2555-4dda-9ff6-060c23eccbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14cfb42-ec3a-4512-b9de-cd5488a61d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify folder that holds tiles in completed dataset\n",
    "\n",
    "#unique positive jpgs (file names with the file extension)\n",
    "unique_positive_jpgs = fc.unique_positive_jpgs_from_parent_directory(args.parent_directory)\n",
    "\n",
    "image_characteristics = fc.image_characteristics(complete_dataset_tiles_folder_path, unique_positive_jpgs)\n",
    "\n",
    "image_characteristics.to_csv('image_characteristics.csv')\n",
    "counterin = 0\n",
    "counternot = 0 \n",
    "\n",
    "#Check to see how many images are not yet in the image characteristics folder (not verified)\n",
    "for unique_jpg in unique_positive_jpgs[:,0]:\n",
    "    if image_characteristics['six_digit_chip_name'].isin([unique_jpg]).any():\n",
    "        counterin += 1\n",
    "    if not image_characteristics['six_digit_chip_name'].isin([unique_jpg]).any():\n",
    "        counternot += 1\n",
    "print(\"images included in the image characteristics csv \",counterin, \\\n",
    "      \"images not included in the image characteristics csv \\ left to be verified\", counternot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1978b3-b5c9-4486-b094-79eddcbfff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for unique_standard_tile_names in tile_names_tile_urls_complete_array_unique_standard_tile_names[:,2]:\n",
    "#    if unique\n",
    "tiles_with_no_images = []\n",
    "tiles_with_images = []\n",
    "for standard_tile_name in tqdm_notebook(image_characteristics.standard_tile_name.unique()): #Iterate over all the possible tiles that could be included in the dataset\n",
    "    print(standard_tile_name)\n",
    "    #get the image characteristics for the images corresponding to each tile\n",
    "    images_in_tile = image_characteristics.loc[image_characteristics.standard_tile_name == standard_tile_name] #get the annotated images corresponding to ech time\n",
    "    indicies = images_in_tile.index\n",
    "    \n",
    "    #get the characteristics for each time\n",
    "    da = xr.open_rasterio(os.path.join(tiles_complete_dataset_path, standard_tile_name +\".tif\"))\n",
    "    tile_band, tile_height, tile_width = da.shape[0], da.shape[1], da.shape[2]\n",
    "    #make the xml for each tile\n",
    "    generate_xml(standard_tile_name, tiles_complete_dataset_path, tiles_xml_complete_dataset_path, tile_band, tile_height, tile_width)\n",
    "    #add data from each image xml to the corresponding tile xml\n",
    "    #for i in indicies:\n",
    "    #    xml_path, root = get_xml_path_from_root_jpg(images_in_tile, i)\n",
    "    #if not images_in_tile.empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c739a-89a0-43bd-8a50-842491ca0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b537bd-1c6d-4d9d-85d3-2ccd8153c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rasterio.open(os.path.join(tiles_complete_dataset_path, os.listdir(tiles_complete_dataset_path)[0]))\n",
    "left = dataset.bounds[0]\n",
    "right = dataset.bounds[2]\n",
    "bottom = dataset.bounds[1]\n",
    "top = dataset.bounds[3]\n",
    "x = dataset.shape[0] \n",
    "y = dataset.shape[1] \n",
    "np.linspace(left, right, num=x-1)# endpoint=True, retstep=False, dtype=None, axis=0)\n",
    "# Read the data\n",
    "## Get tile locations\n",
    "da = xr.open_rasterio(os.path.join(tiles_complete_dataset_path, os.listdir(tiles_complete_dataset_path)[0]))\n",
    "# Compute the lon/lat coordinates with rasterio.warp.transform\n",
    "ny, nx = len(da['y']), len(da['x'])\n",
    "x, y = np.meshgrid(da['x'], da['y'])\n",
    "da.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac75f95a-30a9-44e7-a7c1-cdc80be3cb81",
   "metadata": {},
   "source": [
    "## Combine tiles\n",
    "- For every tile\n",
    "- identify all annotated images (.xmls) corresponding to the tile\n",
    "    - identify the position of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d46a4-6ab2-4420-bcb0-fd8d7558a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jpg = os.path.splitext(base)[0] #name of tif with the extension removed\n",
    "#tile_name_formated_name = jpg.rsplit(\"_\",1)[0] #name of tif with the extensio\n",
    "#https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values\n",
    "df.loc[df['column_name'].isin(some_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061e1b3-54d4-4037-adce-b7af826fd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "DomTree = xml.dom.minidom.parse(\"Catalog.xml\")\n",
    "annotation = DomTree.documentElement\n",
    "\n",
    "filenamelist = annotation.getElementsByTagName('filename') #[<DOM Element: filename at 0x381f788>]\n",
    "filename = filenamelist[0]\n",
    "filename.text()\n",
    "#objectlist = annotation.getElementsByTagName('object')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def newRunRun(folder):\n",
    "    xml_files = glob.glob(folder+\"/*.xml\")\n",
    "    node = None\n",
    "    for xmlFile in xml_files:      \n",
    "        tree = ElementTree.parse(xmlFile)\n",
    "        root = tree.getroot()\n",
    "        if node is None:\n",
    "            node = root\n",
    "        else:\n",
    "            elements = root.find(\"./results\")           \n",
    "            for element in elements._children:\n",
    "                node[1].append(element)                \n",
    "    print ElementTree.tostring(node)\n",
    "    \n",
    "    \n",
    "        xml_file = self.chips_xml_list[i]\n",
    "    # use the parse() function to load and parse an XML file\n",
    "    tree = et.parse(os.path.join(self.chips_xml_dir, xml_file))\n",
    "    root = tree.getroot()         \n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        for name in obj.findall('name'):\n",
    "            if name.text not in correctly_formatted_object:\n",
    "                name.text = object_dict[name.text]\n",
    "\n",
    "        if int(obj.find('difficult').text) == 1:\n",
    "            obj.find('truncated').text = '1'\n",
    "            obj.find('difficult').text = '0'\n",
    "\n",
    "folder = \"resources\"\n",
    "newRunRun(folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964d738-f302-4c46-9cd1-35a2c580b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace <Subscription Key> with your valid subscription key.\n",
    "subscription_key = \"f244aa59ad4f4c05be907b4e78b7c6da\"\n",
    "assert subscription_key\n",
    "\n",
    "vision_base_url = \"https://westcentralus.api.cognitive.microsoft.com/vision/v2.0/\"\n",
    "\n",
    "ocr_url = vision_base_url + \"ocr\"\n",
    "\n",
    "# Set image_url to the URL of an image that you want to analyze.\n",
    "image_url = \"https://cdn-ayb.akinon.net/cms/2019/04/04/e494dce0-1e80-47eb-96c9-448960a71260.jpg\"\n",
    "\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params  = {'language': 'unk', 'detectOrientation': 'true'}\n",
    "data    = {'url': image_url}\n",
    "response = requests.post(ocr_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "\n",
    "analysis = response.json()\n",
    "\n",
    "# Extract the word bounding boxes and text.\n",
    "line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
    "word_infos = []\n",
    "for line in line_infos:\n",
    "    for word_metadata in line:\n",
    "        for word_info in word_metadata[\"words\"]:\n",
    "            word_infos.append(word_info)\n",
    "word_infos\n",
    "\n",
    "# Display the image and overlay it with the extracted text.\n",
    "plt.figure(figsize=(100, 20))\n",
    "image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "ax = plt.imshow(image)\n",
    "texts_boxes = []\n",
    "texts = []\n",
    "for word in word_infos:\n",
    "    bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "    text = word[\"text\"]\n",
    "    origin = (bbox[0], bbox[1])\n",
    "    patch  = Rectangle(origin, bbox[2], bbox[3], fill=False, linewidth=3, color='r')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(origin[0], origin[1], text, fontsize=2, weight=\"bold\", va=\"top\")\n",
    "#     print(bbox)\n",
    "    new_box = [bbox[1], bbox[0], bbox[1]+bbox[3], bbox[0]+bbox[2]]\n",
    "    texts_boxes.append(new_box)\n",
    "    texts.append(text)\n",
    "#     print(text)\n",
    "plt.axis(\"off\")\n",
    "texts_boxes = np.array(texts_boxes)\n",
    "texts_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b2d69-eea5-42a1-aa38-77142901052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.rename_formatted_chips_images_xmls(complete_dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chip Allocate",
   "language": "python",
   "name": "chip_allocate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
