{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29abde2c-fb9e-4cbb-b7bd-c4354a0662ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import fiona #must be import before geopandas\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import re\n",
    "import rtree\n",
    "import shapely\n",
    "import pickle\n",
    "\n",
    "#from cartopy import crs\n",
    "import collections\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "# Standard packages\n",
    "import tempfile\n",
    "import warnings\n",
    "import urllib\n",
    "import shutil\n",
    "\n",
    "# Less standard, but still pip- or conda-installable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import data_eng.az_proc as ap\n",
    "import data_eng.form_calcs as fc\n",
    "\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8d4e743-b543-4119-8ae6-846e28915d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.remove_thumbs(os.path.join(parent_directory,\"verified\",\"complete_dataset\",\"chips_positive\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c74bbdf-8007-47bb-aef4-5d4bd6b57f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = \"//oit-nas-fe13dc.oit.duke.edu//data_commons-borsuk//\"\n",
    "\n",
    "tile_names_tile_urls_complete_array = np.load(\"image_download_azure/tile_name_tile_url_complete_array.npy\")\n",
    "\n",
    "tiles_labeled = \"tile_name_tile_url_labeled.npy\"\n",
    "tiles_labeled_from_complete_set = np.load(tiles_labeled)\n",
    "\n",
    "tracker_file_path = 'outputs/tile_img_annotation_annotator.npy'\n",
    "tile_img_annotation = np.load(tracker_file_path)\n",
    "\n",
    "tiles_errors = 'tile_name_tile_url_error_downloading.npy'\n",
    "tiles_errors = np.load(tiles_errors)\n",
    "\n",
    "#create folder to hold tiles in completed dataset\n",
    "path_to_complete_dataset = \"verified/complete_dataset\"\n",
    "path_to_tiles_folder_complete_dataset = os.path.join(parent_directory, path_to_complete_dataset,\"tiles\")\n",
    "os.makedirs(path_to_tiles_folder_complete_dataset, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0dee68b-7cf3-459b-9472-18f92a5f4a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cell_Features',\n",
       " 'Cell_History',\n",
       " 'CellGrid_15Minute',\n",
       " 'CellGrid_1X1Degree',\n",
       " 'CellGrid_1X2Degree',\n",
       " 'CellGrid_3_75Minute',\n",
       " 'CellGrid_30X60Minute',\n",
       " 'CellGrid_7_5Minute',\n",
       " 'Cell_PolygonAll']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_indicies_path = \"C:/Users/rapiduser/Box/EPA STAR 2019 (Community Resistance to Environmental Disasters)/Data/AST Datasets/MapIndices_National_GDB/MapIndices_National_GDB.gdb\"\n",
    "fiona.listlayers(quad_indicies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b537bd-1c6d-4d9d-85d3-2ccd8153c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([453672.        , 453672.50487684, 453673.00975368, ...,\n",
       "       459778.99024632, 459779.49512316, 459780.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = rasterio.open(os.path.join(path_to_tiles_folder_complete_dataset, os.listdir(path_to_tiles_folder_complete_dataset)[0]))\n",
    "left = dataset.bounds[0]\n",
    "right = dataset.bounds[2]\n",
    "bottom = dataset.bounds[1]\n",
    "top = dataset.bounds[3]\n",
    "x = dataset.shape[0] \n",
    "y = dataset.shape[1] \n",
    "\n",
    "np.linspace(left, right, num=x-1)# endpoint=True, retstep=False, dtype=None, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7661de-3c83-4201-9632-cb3f6810d4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+init=epsg:26911'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "## Get tile locations\n",
    "da = xr.open_rasterio(os.path.join(path_to_tiles_folder_complete_dataset, os.listdir(path_to_tiles_folder_complete_dataset)[0]))\n",
    "# Compute the lon/lat coordinates with rasterio.warp.transform\n",
    "ny, nx = len(da['y']), len(da['x'])\n",
    "x, y = np.meshgrid(da['x'], da['y'])\n",
    "da.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09de96f1-2553-4068-9bc7-27ab6f824987",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_names_tile_urls_complete_array_unique_standard_tile_names = np.load(\"tile_names_tile_urls_complete_array_unique_standard_tile_names.npy\")\n",
    "image_characteristics = pd.read_csv(\"image_characteristics.csv\")\n",
    "\n",
    "#for unique_standard_tile_names in tile_names_tile_urls_complete_array_unique_standard_tile_names[:,2]:\n",
    "#    if unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "089a664a-9051-4ef9-93ab-16df4e001236",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_with_no_images = []\n",
    "tiles_with_images = []\n",
    "for standard_tile_name in tile_names_tile_urls_complete_array_unique_standard_tile_names[:,2]: #Iterate over all the possible tiles that could be included in the dataset\n",
    "    images_in_tile = image_characteristics.loc[image_characteristics[\"standard_tile_name\"] == standard_tile_name] #get the annotated images corresponding to ech time\n",
    "    if not images_in_tile.empty:\n",
    "        tiles_with_no_images.append(standard_tile_name)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3ff2a0c-8ffa-4077-aa27-3925f651081f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//oit-nas-fe13dc.oit.duke.edu//data_commons-borsuk//complete_dataset\\\\nj_60cm_2019_39075_m_3907507_sw_18_060_20190726_000226.xml'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(parent_directory,\"complete_dataset\",\"nj_60cm_2019_39075_m_3907507_sw_18_060_20190726_000226\"+\".xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bfe97-60d4-4ad3-8814-ed56c60028f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values\n",
    "df.loc[df['column_name'].isin(some_values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7cd03-f481-4f41-847f-5aa43225b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Combine tiles\n",
    "\n",
    "- For every tile\n",
    "- identify all annotated images (.xmls) corresponding to the tile\n",
    "    - identify the position of the image\n",
    "    \n",
    "\n",
    "def newRunRun(folder):\n",
    "    xml_files = glob.glob(folder+\"/*.xml\")\n",
    "    node = None\n",
    "    for xmlFile in xml_files:      \n",
    "        tree = ElementTree.parse(xmlFile)\n",
    "        root = tree.getroot()\n",
    "        if node is None:\n",
    "            node = root\n",
    "        else:\n",
    "            elements = root.find(\"./results\")           \n",
    "            for element in elements._children:\n",
    "                node[1].append(element)                \n",
    "    print ElementTree.tostring(node)\n",
    "\n",
    "folder = \"resources\"\n",
    "newRunRun(folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964d738-f302-4c46-9cd1-35a2c580b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# If you are using a Jupyter notebook, uncomment the following line.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Replace <Subscription Key> with your valid subscription key.\n",
    "subscription_key = \"f244aa59ad4f4c05be907b4e78b7c6da\"\n",
    "assert subscription_key\n",
    "\n",
    "vision_base_url = \"https://westcentralus.api.cognitive.microsoft.com/vision/v2.0/\"\n",
    "\n",
    "ocr_url = vision_base_url + \"ocr\"\n",
    "\n",
    "# Set image_url to the URL of an image that you want to analyze.\n",
    "image_url = \"https://cdn-ayb.akinon.net/cms/2019/04/04/e494dce0-1e80-47eb-96c9-448960a71260.jpg\"\n",
    "\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params  = {'language': 'unk', 'detectOrientation': 'true'}\n",
    "data    = {'url': image_url}\n",
    "response = requests.post(ocr_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "\n",
    "analysis = response.json()\n",
    "\n",
    "# Extract the word bounding boxes and text.\n",
    "line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
    "word_infos = []\n",
    "for line in line_infos:\n",
    "    for word_metadata in line:\n",
    "        for word_info in word_metadata[\"words\"]:\n",
    "            word_infos.append(word_info)\n",
    "word_infos\n",
    "\n",
    "# Display the image and overlay it with the extracted text.\n",
    "plt.figure(figsize=(100, 20))\n",
    "image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "ax = plt.imshow(image)\n",
    "texts_boxes = []\n",
    "texts = []\n",
    "for word in word_infos:\n",
    "    bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "    text = word[\"text\"]\n",
    "    origin = (bbox[0], bbox[1])\n",
    "    patch  = Rectangle(origin, bbox[2], bbox[3], fill=False, linewidth=3, color='r')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(origin[0], origin[1], text, fontsize=2, weight=\"bold\", va=\"top\")\n",
    "#     print(bbox)\n",
    "    new_box = [bbox[1], bbox[0], bbox[1]+bbox[3], bbox[0]+bbox[2]]\n",
    "    texts_boxes.append(new_box)\n",
    "    texts.append(text)\n",
    "#     print(text)\n",
    "plt.axis(\"off\")\n",
    "texts_boxes = np.array(texts_boxes)\n",
    "texts_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238ecd92-df33-40f4-8e2a-7efb8da98311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from https://data.cityofnewyork.us/City-Government/Projected-Sea-Level-Rise/6an6-9htp directly...\n",
    "data = gpd.read_file(quad_indicies_path, driver='FileGDB', layer=7)#'CellGrid_7_5Minute')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chip Allocate",
   "language": "python",
   "name": "chip_allocate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
